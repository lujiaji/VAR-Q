{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8accb9",
   "metadata": {},
   "source": [
    "### This notebook displays the basic inference of VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6215a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## 1. Download checkpoints ##################\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import time\n",
    "import torch, torchvision\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import PIL.Image as PImage, PIL.ImageDraw as PImageDraw\n",
    "import importlib\n",
    "project_root = 'VAR-Q'\n",
    "os.chdir(project_root)\n",
    "# Add the VAR-Q directory to the Python path\n",
    "sys.path.append('VAR-Q')\n",
    "\n",
    "setattr(torch.nn.Linear, 'reset_parameters', lambda self: None)     # disable default parameter init for faster speed\n",
    "setattr(torch.nn.LayerNorm, 'reset_parameters', lambda self: None)  # disable default parameter init for faster speed\n",
    "\n",
    "# Import configuration loader and model builder\n",
    "from VAR_Q.config_loader import load_varq_config\n",
    "from VAR.models import build_vae_var_from_config\n",
    "\n",
    "# Load configuration\n",
    "config = load_varq_config(f'VAR-Q/VAR_Q/VAR-raw.json')\n",
    "\n",
    "# Get model depth from config\n",
    "model_depth = config.get_model_config()['depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## 2. Build models ##################\n",
    "assert model_depth in {16, 20, 24, 30, 36}\n",
    "\n",
    "# Get checkpoint paths from config\n",
    "vae_ckpt, var_ckpt = config.get_checkpoint_paths(model_depth)\n",
    "hf_home = config.get_checkpoint_config()['hf_home']\n",
    "\n",
    "# Download checkpoints if they don't exist\n",
    "if not osp.exists(vae_ckpt): \n",
    "    print(f\"Downloading VAE checkpoint from {hf_home}/{vae_ckpt}\")\n",
    "    os.system(f'wget {hf_home}/{vae_ckpt}')\n",
    "if not osp.exists(var_ckpt): \n",
    "    print(f\"Downloading VAR checkpoint from {hf_home}/{var_ckpt}\")\n",
    "    os.system(f'wget {hf_home}/{var_ckpt}')\n",
    "\n",
    "# Get device from config\n",
    "device = config.get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Build models using configuration\n",
    "if 'vae' not in globals() or 'var' not in globals():\n",
    "    print(\"Building models from configuration...\")\n",
    "    vae, var = build_vae_var_from_config(config.config, device=device)\n",
    "\n",
    "# Load checkpoints\n",
    "print(\"Loading checkpoints...\")\n",
    "vae.load_state_dict(torch.load(vae_ckpt, map_location='cpu'), strict=True)\n",
    "var.load_state_dict(torch.load(var_ckpt, map_location='cpu'), strict=True)\n",
    "vae.eval(), var.eval()\n",
    "for p in vae.parameters(): p.requires_grad_(False)\n",
    "for p in var.parameters(): p.requires_grad_(False)\n",
    "print(f'prepare finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# 3. Sample with classifier-free guidance #############################\n",
    "# Get inference parameters from config\n",
    "inference_config = config.get_inference_config()\n",
    "seed = inference_config['seed']\n",
    "cfg = inference_config['cfg']\n",
    "top_k = inference_config['top_k']\n",
    "top_p = inference_config['top_p']\n",
    "more_smooth = inference_config['more_smooth']\n",
    "class_labels = (980, 980, 437, 437, 22, 22, 562, 562)  #@param {type:\"raw\"}\n",
    "\n",
    "print(f\"Inference parameters:\")\n",
    "print(f\"  Seed: {seed}\")\n",
    "print(f\"  CFG: {cfg}\")\n",
    "print(f\"  Top-k: {top_k}\")\n",
    "print(f\"  Top-p: {top_p}\")\n",
    "print(f\"  More smooth: {more_smooth}\")\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Run faster\n",
    "tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = bool(tf32)\n",
    "torch.backends.cuda.matmul.allow_tf32 = bool(tf32)\n",
    "torch.set_float32_matmul_precision('high' if tf32 else 'highest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# 4. Generate images #############################\n",
    "# sample\n",
    "B = len(class_labels)\n",
    "label_B: torch.LongTensor = torch.tensor(class_labels, device=device)\n",
    "with torch.inference_mode():\n",
    "    with torch.autocast('cuda', enabled=True, dtype=torch.float16, cache_enabled=True):    # using bfloat16 can be faster\n",
    "        start_time = time.time()\n",
    "        recon_B3HW = var.autoregressive_infer_cfg(B=B, label_B=label_B, cfg=cfg, top_k=top_k, top_p=top_p, g_seed=seed, more_smooth=more_smooth)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "\n",
    "chw = torchvision.utils.make_grid(recon_B3HW, nrow=8, padding=0, pad_value=1.0)\n",
    "chw = chw.permute(1, 2, 0).mul_(255).cpu().numpy()\n",
    "chw = PImage.fromarray(chw.astype(np.uint8))\n",
    "chw.save('recon_B3HW.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
